{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Subreddit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, the cleaned data will be used to train and evaluate two learning algorithms, namely Multinomial Naive Bayes and Logistic Regression in their performance to accurately classify either r/Android or r/Apple subreddit posts. The models will be evaluated based on their cross-validation scores to identify a production model to score the test data.\n",
    "\n",
    "### Contents:\n",
    "- [Pre-processing](#Pre-processing)\n",
    "- [Modelling](#Modelling)\n",
    "- [Production Model](#Production-Model)\n",
    "- [Conclusion and Recommendations](#Conclusion-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import string\n",
    "import warnings\n",
    "\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, FunctionTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer, ENGLISH_STOP_WORDS\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import regex as re\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('ticks')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv('../data/combined_subreddits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing helps to break down each sentence into words to prepare the data for vectorizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+', gaps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['tokens'] = combined_df['text_title'].map(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>text_title</th>\n",
       "      <th>text_length</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>Note 1. Join our IRC, and Telegram chat-rooms!...</td>\n",
       "      <td>162</td>\n",
       "      <td>[Note, 1, Join, our, IRC, and, Telegram, chat,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>394</td>\n",
       "      <td>28</td>\n",
       "      <td>pinionist</td>\n",
       "      <td>Google Maps is getting dedicated car mode UI</td>\n",
       "      <td>9</td>\n",
       "      <td>[Google, Maps, is, getting, dedicated, car, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1077</td>\n",
       "      <td>61</td>\n",
       "      <td>apmcruZ</td>\n",
       "      <td>Tasker lets you intercept Samsung S Pen gestu...</td>\n",
       "      <td>14</td>\n",
       "      <td>[Tasker, lets, you, intercept, Samsung, S, Pen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1337</td>\n",
       "      <td>184</td>\n",
       "      <td>efbo</td>\n",
       "      <td>22% off nearly everything in European Google ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[22, off, nearly, everything, in, European, Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>294</td>\n",
       "      <td>170</td>\n",
       "      <td>darkstarrising</td>\n",
       "      <td>The new Galaxy S20 FE: $100 off at Amazon and...</td>\n",
       "      <td>13</td>\n",
       "      <td>[The, new, Galaxy, S20, FE, 100, off, at, Amaz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit  upvote_ratio  score  num_comments          author  \\\n",
       "0          0          0.81     14            48   AutoModerator   \n",
       "1          0          0.97    394            28       pinionist   \n",
       "2          0          0.97   1077            61         apmcruZ   \n",
       "3          0          0.92   1337           184            efbo   \n",
       "4          0          0.93    294           170  darkstarrising   \n",
       "\n",
       "                                          text_title  text_length  \\\n",
       "0  Note 1. Join our IRC, and Telegram chat-rooms!...          162   \n",
       "1       Google Maps is getting dedicated car mode UI            9   \n",
       "2   Tasker lets you intercept Samsung S Pen gestu...           14   \n",
       "3   22% off nearly everything in European Google ...            9   \n",
       "4   The new Galaxy S20 FE: $100 off at Amazon and...           13   \n",
       "\n",
       "                                              tokens  \n",
       "0  [Note, 1, Join, our, IRC, and, Telegram, chat,...  \n",
       "1  [Google, Maps, is, getting, dedicated, car, mo...  \n",
       "2  [Tasker, lets, you, intercept, Samsung, S, Pen...  \n",
       "3  [22, off, nearly, everything, in, European, Go...  \n",
       "4  [The, new, Galaxy, S20, FE, 100, off, at, Amaz...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing/ Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizing and stemming are two forms of shortening words to combine similar forms of the same word. The difference in these two methods is that lemmatizing take words and attempt to return their base/dictionary form of a word, while stemming take words and attempt to return a base form of the word which is more cruder but result in faster processing speed. \n",
    "\n",
    "Lemmatizing is usually the more correct and precise way of handling things from a grammatical/morphological point of view and hence will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to take in text input and output string of lemmatized words\n",
    "\n",
    "def lemm(x):\n",
    "\n",
    "    # lemmatize words\n",
    "    lemm_words = [lemmatizer.lemmatize(word.lower()) for word in x]\n",
    "    \n",
    "    # return lemmatized words in a string\n",
    "    return ' '.join(lemm_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['text_lemm'] = combined_df['tokens'].map(lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>text_title</th>\n",
       "      <th>text_length</th>\n",
       "      <th>tokens</th>\n",
       "      <th>text_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>Note 1. Join our IRC, and Telegram chat-rooms!...</td>\n",
       "      <td>162</td>\n",
       "      <td>[Note, 1, Join, our, IRC, and, Telegram, chat,...</td>\n",
       "      <td>note 1 join our irc and telegram chat room ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>394</td>\n",
       "      <td>28</td>\n",
       "      <td>pinionist</td>\n",
       "      <td>Google Maps is getting dedicated car mode UI</td>\n",
       "      <td>9</td>\n",
       "      <td>[Google, Maps, is, getting, dedicated, car, mo...</td>\n",
       "      <td>google map is getting dedicated car mode ui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1077</td>\n",
       "      <td>61</td>\n",
       "      <td>apmcruZ</td>\n",
       "      <td>Tasker lets you intercept Samsung S Pen gestu...</td>\n",
       "      <td>14</td>\n",
       "      <td>[Tasker, lets, you, intercept, Samsung, S, Pen...</td>\n",
       "      <td>tasker let you intercept samsung s pen gesture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1337</td>\n",
       "      <td>184</td>\n",
       "      <td>efbo</td>\n",
       "      <td>22% off nearly everything in European Google ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[22, off, nearly, everything, in, European, Go...</td>\n",
       "      <td>22 off nearly everything in european google store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>294</td>\n",
       "      <td>170</td>\n",
       "      <td>darkstarrising</td>\n",
       "      <td>The new Galaxy S20 FE: $100 off at Amazon and...</td>\n",
       "      <td>13</td>\n",
       "      <td>[The, new, Galaxy, S20, FE, 100, off, at, Amaz...</td>\n",
       "      <td>the new galaxy s20 fe 100 off at amazon and be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit  upvote_ratio  score  num_comments          author  \\\n",
       "0          0          0.81     14            48   AutoModerator   \n",
       "1          0          0.97    394            28       pinionist   \n",
       "2          0          0.97   1077            61         apmcruZ   \n",
       "3          0          0.92   1337           184            efbo   \n",
       "4          0          0.93    294           170  darkstarrising   \n",
       "\n",
       "                                          text_title  text_length  \\\n",
       "0  Note 1. Join our IRC, and Telegram chat-rooms!...          162   \n",
       "1       Google Maps is getting dedicated car mode UI            9   \n",
       "2   Tasker lets you intercept Samsung S Pen gestu...           14   \n",
       "3   22% off nearly everything in European Google ...            9   \n",
       "4   The new Galaxy S20 FE: $100 off at Amazon and...           13   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Note, 1, Join, our, IRC, and, Telegram, chat,...   \n",
       "1  [Google, Maps, is, getting, dedicated, car, mo...   \n",
       "2  [Tasker, lets, you, intercept, Samsung, S, Pen...   \n",
       "3  [22, off, nearly, everything, in, European, Go...   \n",
       "4  [The, new, Galaxy, S20, FE, 100, off, at, Amaz...   \n",
       "\n",
       "                                           text_lemm  \n",
       "0  note 1 join our irc and telegram chat room ple...  \n",
       "1        google map is getting dedicated car mode ui  \n",
       "2  tasker let you intercept samsung s pen gesture...  \n",
       "3  22 off nearly everything in european google store  \n",
       "4  the new galaxy s20 fe 100 off at amazon and be...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customise stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords are very common words that does not add meaning to the documents and hence has no value in helping to classify the documents. The NLTK stopword list was used to remove the highly common words during vectorizing pre-processing step below. From the EDA process, additional words which come up frequently in both subreddits such as \"app\" and \"iphone\" would be removed as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# nltk stopword list\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# add additional stopwords which are common across r/apple and r/android\n",
    "additional_stopwords = {'app','iphone'}\n",
    "stop_words = stop_words.union(additional_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_df[['text_lemm','score','num_comments']] \n",
    "y = combined_df['subreddit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Feature Selection Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification metric used will be the **ROC-AUC (Receiver Operating Characteristics - Area Under Curve)** which is a common classification metric as it tells how much a model is capable of distinguishing between classes, in our case postings between r/apple and r/android. The target success criteria for the models is to at least achieve a ROC-AUC score of 0.95 (ideal being 1.0).\n",
    "\n",
    "Two learning algorithms are evaluated: 1) **multinomial Naive Bayes**, and 2) **logistic regression**, using the following combination of preprocessing methods and hyperparameters in the gridsearch param_grid:\n",
    "\n",
    "- `Vectoriser`: count vectorizer/ TF-IDF vectorizer\n",
    "- `Max features`: 2000/ 3000/ 4000/ 5000/ 5500\n",
    "- `Max document frequency`: 0.1/ 0.5/ 0.9\n",
    "- `Min document frequency`: 1/ 2/ 3\n",
    "- `N-gram range`: (1,1)/ (1,2)/ (1,3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.546994\n",
       "0    0.453006\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model would predict class 1 (r/apple) for all posts, since it has a slightly higher percentage (54.7%) than r/android. Hence, baseline accuracy score is 54.7%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-title as predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1350 out of 1350 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Best score: 0.9864384426643573\n",
      "{'vectorizer': TfidfVectorizer(max_df=0.5, max_features=5000, min_df=2, ngram_range=(1, 3),\n",
      "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
      "                            'ain', 'all', 'am', 'an', 'and', 'any', 'app',\n",
      "                            'are', 'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                            'because', 'been', 'before', 'being', 'below',\n",
      "                            'between', 'both', 'but', 'by', 'can', 'couldn', ...}), 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 5000, 'vectorizer__min_df': 2, 'vectorizer__ngram_range': (1, 3)}\n",
      "\\Score on training set: 0.9979564808902477\n"
     ]
    }
   ],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x:x['text_lemm'], validate=False)),\n",
    "    ('vectorizer', None),\n",
    "    ('logreg', LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "# specify the param grid for gridsearch, which includes different feature selection methods\n",
    "pipe_params = [{\n",
    "   \n",
    "        'vectorizer': [CountVectorizer(stop_words = stop_words),\n",
    "                       TfidfVectorizer(stop_words = stop_words)],\n",
    "        'vectorizer__max_features': [2000, 3000, 4000, 5000, 5500],\n",
    "        'vectorizer__max_df': [0.1, 0.5, 0.9],\n",
    "        'vectorizer__min_df': [1, 2, 3],    \n",
    "        'vectorizer__ngram_range': [(1,1), (1,2),(1,3)]\n",
    "        \n",
    "    }]\n",
    "\n",
    "# perform gridsearch for the best feature selection, model, etc\n",
    "gs_text = GridSearchCV(pipe, cv=5, param_grid=pipe_params, scoring = 'roc_auc', verbose=True)\n",
    "gs_text.fit(X_train, y_train)\n",
    "print(f\"\\Best score: {gs_text.best_score_}\")\n",
    "print(gs_text.best_params_)\n",
    "    \n",
    "print(f\"\\Score on training set: {gs_text.score(X_train, y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1350 out of 1350 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Best score: 0.982526759038753\n",
      "{'vectorizer': TfidfVectorizer(max_df=0.5, max_features=5000, min_df=2, ngram_range=(1, 3),\n",
      "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
      "                            'ain', 'all', 'am', 'an', 'and', 'any', 'app',\n",
      "                            'are', 'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                            'because', 'been', 'before', 'being', 'below',\n",
      "                            'between', 'both', 'but', 'by', 'can', 'couldn', ...}), 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 5000, 'vectorizer__min_df': 2, 'vectorizer__ngram_range': (1, 3)}\n",
      "\\Score on training set: 0.997029856233432\n"
     ]
    }
   ],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x:x['text_lemm'], validate=False)),\n",
    "    ('vectorizer', None),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# specify the param grid for gridsearch, which includes different feature selection methods\n",
    "pipe_params = [{\n",
    "   \n",
    "        'vectorizer': [CountVectorizer(stop_words = stop_words),\n",
    "                       TfidfVectorizer(stop_words = stop_words)],\n",
    "        'vectorizer__max_features': [2000, 3000, 4000, 5000, 5500],\n",
    "        'vectorizer__max_df': [0.1, 0.5, 0.9],\n",
    "        'vectorizer__min_df': [1, 2, 3],    \n",
    "        'vectorizer__ngram_range': [(1,1), (1,2),(1,3)]\n",
    "        \n",
    "    }]\n",
    "\n",
    "# perform gridsearch for the best feature selection, model, etc\n",
    "gs_text = GridSearchCV(pipe, cv=5, param_grid=pipe_params, scoring = 'roc_auc', verbose=True)\n",
    "gs_text.fit(X_train, y_train)\n",
    "print(f\"\\Best score: {gs_text.best_score_}\")\n",
    "print(gs_text.best_params_)\n",
    "    \n",
    "print(f\"\\Score on training set: {gs_text.score(X_train, y_train)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score and comment counts as predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score and comment counts for both subreddits were added to the predictors to examine whether they help to improve the classifiers' performance. The numerical features were scaled and transformed using RobustScaler to reduce the influence of the extreme outliers (shown by earlier EDA) by removing the median and scaling the data according to the interquartile range.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1350 out of 1350 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Best score: 0.9849166486252436\n",
      "{'union__text__vectorizer': TfidfVectorizer(max_df=0.5, max_features=2000, min_df=2, ngram_range=(1, 3),\n",
      "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
      "                            'ain', 'all', 'am', 'an', 'and', 'any', 'app',\n",
      "                            'are', 'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                            'because', 'been', 'before', 'being', 'below',\n",
      "                            'between', 'both', 'but', 'by', 'can', 'couldn', ...}), 'union__text__vectorizer__max_df': 0.5, 'union__text__vectorizer__max_features': 2000, 'union__text__vectorizer__min_df': 2, 'union__text__vectorizer__ngram_range': (1, 3)}\n",
      "\\Score on training set: 0.9972545250887388\n"
     ]
    }
   ],
   "source": [
    "# text pipeline\n",
    "text_pipe = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x:x['text_lemm'], validate=False)),\n",
    "    ('vectorizer', None)\n",
    "])\n",
    "\n",
    "# numerical pipeline\n",
    "numerical_pipe = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x:x[['score', 'num_comments']], validate = False)),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# combine pipelines with FeatureUnion\n",
    "overall_pipe = Pipeline([\n",
    "    ('union', FeatureUnion([('text',text_pipe),\n",
    "                            ('numerical',numerical_pipe)])),\n",
    "    ('logreg', LogisticRegression(solver='liblinear'))])\n",
    "\n",
    "\n",
    "# specify the param grid for gridsearch, which includes different feature selection methods\n",
    "pipe_params = [{\n",
    "   \n",
    "        'union__text__vectorizer': [CountVectorizer(stop_words = stop_words),\n",
    "                                    TfidfVectorizer(stop_words = stop_words)],\n",
    "        'union__text__vectorizer__max_features': [2000, 3000, 4000, 5000, 5500],\n",
    "        'union__text__vectorizer__max_df': [0.1, 0.5, 0.9],\n",
    "        'union__text__vectorizer__min_df': [1, 2, 3],    \n",
    "        'union__text__vectorizer__ngram_range': [(1,1), (1,2),(1,3)]\n",
    "        \n",
    "    }]\n",
    "\n",
    "# perform gridsearch for the best feature selection, model, etc\n",
    "gs_text_num = GridSearchCV(overall_pipe, cv=5, param_grid=pipe_params, scoring = 'roc_auc', verbose=True)\n",
    "gs_text_num.fit(X_train, y_train)\n",
    "print(f\"\\Best score: {gs_text_num.best_score_}\")\n",
    "print(gs_text_num.best_params_)\n",
    "    \n",
    "print(f\"\\Score on training set: {gs_text_num.score(X_train, y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1350 out of 1350 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Best score: 0.9829836039546798\n",
      "{'union__text__vectorizer': TfidfVectorizer(max_df=0.5, max_features=5000, min_df=2, ngram_range=(1, 3),\n",
      "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
      "                            'ain', 'all', 'am', 'an', 'and', 'any', 'app',\n",
      "                            'are', 'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                            'because', 'been', 'before', 'being', 'below',\n",
      "                            'between', 'both', 'but', 'by', 'can', 'couldn', ...}), 'union__text__vectorizer__max_df': 0.5, 'union__text__vectorizer__max_features': 5000, 'union__text__vectorizer__min_df': 2, 'union__text__vectorizer__ngram_range': (1, 3)}\n",
      "\\Score on training set: 0.9971835770291682\n"
     ]
    }
   ],
   "source": [
    "# text pipeline\n",
    "text_pipe = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x:x['text_lemm'], validate=False)),\n",
    "    ('vectorizer', None)\n",
    "])\n",
    "\n",
    "# numerical pipeline\n",
    "numerical_pipe = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x:x[['score', 'num_comments']], validate = False)),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# combine pipelines with FeatureUnion\n",
    "overall_pipe = Pipeline([\n",
    "    ('union', FeatureUnion([('text',text_pipe),\n",
    "                            ('numerical',numerical_pipe)])),\n",
    "    ('nb', MultinomialNB())])\n",
    "\n",
    "\n",
    "# specify the param grid for gridsearch, which includes different feature selection methods\n",
    "pipe_params = [{\n",
    "   \n",
    "        'union__text__vectorizer': [CountVectorizer(stop_words = stop_words),\n",
    "                                    TfidfVectorizer(stop_words = stop_words)],\n",
    "        'union__text__vectorizer__max_features': [2000, 3000, 4000, 5000, 5500],\n",
    "        'union__text__vectorizer__max_df': [0.1, 0.5, 0.9],\n",
    "        'union__text__vectorizer__min_df': [1, 2, 3],    \n",
    "        'union__text__vectorizer__ngram_range': [(1,1), (1,2),(1,3)]\n",
    "        \n",
    "    }]\n",
    "\n",
    "# perform gridsearch for the best feature selection, model, etc\n",
    "gs_text_num = GridSearchCV(overall_pipe, cv=5, param_grid=pipe_params, scoring = 'roc_auc', verbose=True)\n",
    "gs_text_num.fit(X_train, y_train)\n",
    "print(f\"\\Best score: {gs_text_num.best_score_}\")\n",
    "print(gs_text_num.best_params_)\n",
    "    \n",
    "print(f\"\\Score on training set: {gs_text_num.score(X_train, y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model results are sumamrised in the table below. In general, the performance of all four models are fairly similar with Logistic Regression models slightly outperforming Multinomial Naive Bayes models under the cross validation scores. The variance between the training and cross-validation scores are about 1% which indicates good generalizability of the models. \n",
    "\n",
    "For logistic regression, it can also be seen that adding the score and comment count numerical features did not improve the cross validation scores. Hence, the **Logistic Regression model using title-text as a predictor** will be chosen for the production model. Regularisation techniques such as Lasso and Ridge will be examined next to further improve the generalizability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Predictors |Model |Train Score |Cross Validation Score  \t|   \t|\n",
    "|---\t|---\t      |---\t        |---\t|---\t|\n",
    "|Text-title \t|Logistic Regression   \t      |0.998          \t|0.986   \t|   \t|\n",
    "|Text-title   \t|Multinomial Naive Bayes   \t      |0.997   \t        |0.983   \t|   \t|\n",
    "|Text-title + score and comment counts    |Logistic Regression   \t      |0.997   \t        |0.985   \t|   \t|\n",
    "|Text-title + score and comment counts \t|Multinomial Naive Bayes   \t      |0.997          \t|0.983   \t|   \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate tvec model with best parameters.\n",
    "tvec = TfidfVectorizer(max_df=0.5, max_features=5000, min_df=2, ngram_range=(1,3), stop_words=stop_words)\n",
    "\n",
    "# Fit and transform model\n",
    "X_train_tvec = tvec.fit_transform(X_train['text_lemm'], y_train).todense()\n",
    "X_test_tvec = tvec.transform(X_test['text_lemm']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate logistic regression model\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# specify param grid\n",
    "log_reg_params = {\n",
    "    'C': np.linspace(0.001,10),\n",
    "    'penalty': [\"l1\", \"l2\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9867828462149095\n",
      "{'C': 2.653795918367347, 'penalty': 'l2'}\n",
      "Score on training set: 0.9994463901412297\n",
      "Score on testing set: 0.9807824296499656\n"
     ]
    }
   ],
   "source": [
    "# perform grid search \n",
    "gs_logreg = GridSearchCV(logreg, param_grid=log_reg_params, scoring = 'roc_auc',cv=5)\n",
    "gs_logreg.fit(X_train_tvec, y_train)\n",
    "\n",
    "print(f\"Best score: {gs_logreg.best_score_}\")\n",
    "print(gs_logreg.best_params_)\n",
    "\n",
    "print(f\"Score on training set: {gs_logreg.score(X_train_tvec, y_train)}\")\n",
    "print(f\"Score on testing set: {gs_logreg.score(X_test_tvec, y_test)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on training set: 0.9912408759124087\n",
      "Accuracy Score on testing set: 0.9475218658892128\n"
     ]
    }
   ],
   "source": [
    "# Re-initialise logistic regression with the best params\n",
    "logreg = LogisticRegression(C=2.653795918367347, penalty = \"l2\", solver='liblinear')\n",
    "logreg.fit(X_train_tvec, y_train)\n",
    "\n",
    "print('Accuracy Score on training set:', logreg.score(X_train_tvec, y_train))\n",
    "print('Accuracy Score on testing set:', logreg.score(X_test_tvec, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model performed well against the unseen test dataset after ridge regularisation (L2 penalty) with an ROC-AUC score of 0.981. The accuracy score is also high at 94.8% which significantly outperforms the baseline accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_r/android</th>\n",
       "      <th>predict_r/apple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_r/android</th>\n",
       "      <td>143</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_r/apple</th>\n",
       "      <td>6</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  predict_r/android  predict_r/apple\n",
       "actual_r/android                143               12\n",
       "actual_r/apple                    6              182"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate confusion matrix\n",
    "preds_text = logreg.predict(X_test_tvec)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds_text) \n",
    "cm_df = pd.DataFrame(data = cm, columns = ['predict_r/android','predict_r/apple'], index =['actual_r/android','actual_r/apple'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above confusion matrix, it can be observed that the model has very high accuracy in classifying r/apple posts with a misclassfication rate of only 3.3% while the misclassification rate for r/android is slightly higher at 7.7% but still within acceptable boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with column for predicted values\n",
    "results = pd.DataFrame(preds_text, columns=['predicted'], index = y_test.index)\n",
    "\n",
    "# Create column for actual values\n",
    "results['actual'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predicted  actual\n",
       "1090          0       1\n",
       "1279          0       1\n",
       "1626          0       1\n",
       "818           0       1\n",
       "1536          0       1\n",
       "1501          0       1\n",
       "491           1       0\n",
       "189           1       0\n",
       "401           1       0\n",
       "600           1       0\n",
       "560           1       0\n",
       "288           1       0\n",
       "546           1       0\n",
       "95            1       0\n",
       "34            1       0\n",
       "755           1       0\n",
       "21            1       0\n",
       "683           1       0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all indices where predicted and true results aren't the same\n",
    "results[results['predicted']!=results['actual']].sort_values(\"predicted\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x post from r android this feature not being on the ipad is a deal breaker'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of misclassifying r/apple (actual) to r/android\n",
    "combined_df['text_lemm'][1279]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i ve been an android user since the beginning i ve always maintained that android is the way to go because of the innovation within that ecosystem the openness and in my mind android wa always one step ahead of io fast forward to today and thing are starting to feel very different we have the new apple watch that wa announced yesterday which is looking better and better hugely customizable and just a very cool looking device the only problem is you need an iphone to own one fortunately the parity between phone is almost identical these day most popular apps are on both each allow you a good level of customization now io 14 added home screen widget for instance where s the great pixel watch even out of the gate i can t imagine it doing an 8th of what the apple watch doe because they ve been iterating on it for year the wear o on the other hand is just barely not abandonware then you have all the excellent apple service popping up apple for tv fitness for connected exercise video and such instant update on the o release and oh yeah that bad as looking watch seems to be a super attractive space to move in to your move google what s the deal the latest android 11 is pretty blah to me where s the exciting new innovation and feature since when did google start playing it safe and apple start pushing the envelope not trying to start a holy war just having thought apple watch is what s starting to tempt me away from android'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of misclassifying r/android (actual) to r/apple\n",
    "combined_df['text_lemm'][189]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reddit get it app to 50 million play store downloads mostly by making the mobile web experience miserable'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of misclassifying r/android (actual) to r/apple\n",
    "combined_df['text_lemm'][401]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A deeper examination of the misclassifications reveal that most of the misclassifications are a result of common words appearing between the 2 subreddits e.g. discussion between android and apple product features in r/apple and vice versa. For r/android, there were also a few posts with short text without strong word features which might explain the higher misclassifications.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top word features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coefficient column labels\n",
    "index = tvec.get_feature_names()\n",
    "\n",
    "# Generate dataframe of features with coefficients\n",
    "logreg_coef_df = pd.DataFrame(logreg.coef_[0],\n",
    "                         columns=[\"coef\"],\n",
    "                         index=index)\n",
    "# sort for highest coefficient\n",
    "logreg_coef_df = logreg_coef_df.sort_values(\"coef\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# isolate top and bottom coefficients\n",
    "logreg_coef_odds = pd.concat(objs=[logreg_coef_df.head(10), logreg_coef_df.tail(10)])\n",
    "\n",
    "# plot most significant coefficients\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "sns.barplot(data=logreg_coef_odds,\n",
    "            x=\"coef\",\n",
    "            y=logreg_coef_odds.index,\n",
    "            palette=\"RdBu_r\")\n",
    "\n",
    "plt.title(\"Top Features for Classifying Subreddit\", size=20)\n",
    "plt.yticks(size=12)\n",
    "plt.xticks(size=12)\n",
    "plt.ylabel(\"Word Feature\", size=16)\n",
    "plt.xlabel(\"Model Coefficient\\n(Log-Odds of being from r/Apple)\", size=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above bar chart, it is interesting to note that some of the top 10 keywords for classifying r/Apple (positive class '1') e.g. \"mac\", \"12\", \"widgets\" and \"airpods\" are not from the top 10 common words in r/Apple in earlier EDA, which could be attributed to the TF-IDF vectorizer according higher weights to rarer words which appear in just a handful of documents. For words with the lowest coefficients, most of them actually also appeared in the top 10 common words in r/Android which helped to separate between classes. \n",
    " \n",
    "The logistic regression model coefficients corresponds to the log odds of the posting being from r/Apple as word feature increases by 1 unit, all things remaining constant, and they could be exponentiated to derive the real odds. For example, as 'io' word feature increases by 1 unit, the log-odds of the post being from r/Apple subreddit increases by 4.5 times (or 89 times as likely)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>9.320934</td>\n",
       "      <td>11169.414533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>io</th>\n",
       "      <td>4.489244</td>\n",
       "      <td>89.054067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.963875</td>\n",
       "      <td>19.372891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.930958</td>\n",
       "      <td>18.745571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipad</th>\n",
       "      <td>2.620701</td>\n",
       "      <td>13.745352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coef          odds\n",
       "apple  9.320934  11169.414533\n",
       "io     4.489244     89.054067\n",
       "12     2.963875     19.372891\n",
       "14     2.930958     18.745571\n",
       "ipad   2.620701     13.745352"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute odds from model coefficients\n",
    "logreg_coef_odds[\"odds\"] = logreg_coef_odds.apply(lambda x: np.exp(x))\n",
    "logreg_coef_odds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>galaxy</th>\n",
       "      <td>-3.694782</td>\n",
       "      <td>0.024853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixel</th>\n",
       "      <td>-3.778071</td>\n",
       "      <td>0.022867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>-4.098110</td>\n",
       "      <td>0.016604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>-5.389341</td>\n",
       "      <td>0.004565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>android</th>\n",
       "      <td>-6.595476</td>\n",
       "      <td>0.001367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef      odds\n",
       "galaxy  -3.694782  0.024853\n",
       "pixel   -3.778071  0.022867\n",
       "samsung -4.098110  0.016604\n",
       "google  -5.389341  0.004565\n",
       "android -6.595476  0.001367"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Odds of word features with lowest coefficients\n",
    "logreg_coef_odds.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four classification models using natural language processing techniques were evaluated in their predictive performance to correctly classify r/Apple and r/Android subreddit posts. The Logistic Regression model with text & title feature as predictor slightly outperformed the other models with a high cross-validation ROC-AUC score of 0.986. \n",
    "\n",
    "The model's performance against unseen test data was maintained at a high ROC-AUC score of 0.981 indicating good model generalizability, with corresponding overall accuracy of 94.8% and a very low misclassification rate of r/Apple and r/Android subreddit posts at 3.3% and 7.7% respectively. It was found that most of the misclassifications are a result of common words appearing between the 2 subreddits e.g. discussion between android and apple product features in r/apple and vice versa, or short text without strong word features. \n",
    "\n",
    "To further improve the logistic regression classifier's performance, additional features could be explored e.g. a bigger corpus that incorporates more vocabulary on technology by extracting the text of the posts' comments to address the model's shortcomings at classifying posts with short text, or conducting sentiment analysis on the text features as some of the posts could be personal rants against some products.\n",
    "\n",
    "Additionally, the data could be trained on different classifier models e.g. Subject Vector Classifier or Random Forests to compare their classification performance.  \n",
    "\n",
    "Lastly, in order to maintain the classifier's performance, new data should be continued to be pulled periodically to add to the dataset, so as to account for changing trends in technology topics in r/Apple and r/Android.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
