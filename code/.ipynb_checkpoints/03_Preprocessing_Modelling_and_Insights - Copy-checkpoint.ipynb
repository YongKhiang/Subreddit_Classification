{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Subreddit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import string\n",
    "import warnings\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, FunctionTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer, ENGLISH_STOP_WORDS\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import regex as re\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('ticks')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv('../data/combined_subreddits_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing helps to break down each sentence into words to prepare the data for vectorizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+', gaps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['tokens'] = combined_df['text_title'].map(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>text_title</th>\n",
       "      <th>text_length</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>Note 1. Join our IRC, and Telegram chat-rooms!...</td>\n",
       "      <td>162</td>\n",
       "      <td>[Note, 1, Join, our, IRC, and, Telegram, chat,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>394</td>\n",
       "      <td>28</td>\n",
       "      <td>pinionist</td>\n",
       "      <td>Google Maps is getting dedicated car mode UI</td>\n",
       "      <td>9</td>\n",
       "      <td>[Google, Maps, is, getting, dedicated, car, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1077</td>\n",
       "      <td>61</td>\n",
       "      <td>apmcruZ</td>\n",
       "      <td>Tasker lets you intercept Samsung S Pen gestu...</td>\n",
       "      <td>14</td>\n",
       "      <td>[Tasker, lets, you, intercept, Samsung, S, Pen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1337</td>\n",
       "      <td>184</td>\n",
       "      <td>efbo</td>\n",
       "      <td>22% off nearly everything in European Google ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[22, off, nearly, everything, in, European, Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>294</td>\n",
       "      <td>170</td>\n",
       "      <td>darkstarrising</td>\n",
       "      <td>The new Galaxy S20 FE: $100 off at Amazon and...</td>\n",
       "      <td>13</td>\n",
       "      <td>[The, new, Galaxy, S20, FE, 100, off, at, Amaz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit  upvote_ratio  score  num_comments          author  \\\n",
       "0          1          0.81     14            48   AutoModerator   \n",
       "1          1          0.97    394            28       pinionist   \n",
       "2          1          0.97   1077            61         apmcruZ   \n",
       "3          1          0.92   1337           184            efbo   \n",
       "4          1          0.93    294           170  darkstarrising   \n",
       "\n",
       "                                          text_title  text_length  \\\n",
       "0  Note 1. Join our IRC, and Telegram chat-rooms!...          162   \n",
       "1       Google Maps is getting dedicated car mode UI            9   \n",
       "2   Tasker lets you intercept Samsung S Pen gestu...           14   \n",
       "3   22% off nearly everything in European Google ...            9   \n",
       "4   The new Galaxy S20 FE: $100 off at Amazon and...           13   \n",
       "\n",
       "                                              tokens  \n",
       "0  [Note, 1, Join, our, IRC, and, Telegram, chat,...  \n",
       "1  [Google, Maps, is, getting, dedicated, car, mo...  \n",
       "2  [Tasker, lets, you, intercept, Samsung, S, Pen...  \n",
       "3  [22, off, nearly, everything, in, European, Go...  \n",
       "4  [The, new, Galaxy, S20, FE, 100, off, at, Amaz...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing/ Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizing and stemming are two forms of shortening words to combine similar forms of the same word. The difference in these two methods is that lemmatizing take words and attempt to return their base/dictionary form of a word, while stemming take words and attempt to return a base form of the word which is more cruder but result in faster processing speed. \n",
    "\n",
    "Lemmatizing is usually the more correct and precise way of handling things from a grammatical/morphological point of view and hence will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to take in text input and output string of lemmatized words\n",
    "\n",
    "def lemm(x):\n",
    "\n",
    "    # lemmatize words\n",
    "    lemm_words = [lemmatizer.lemmatize(word.lower()) for word in x]\n",
    "    \n",
    "    # return lemmatized words in a string\n",
    "    return ' '.join(lemm_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['text_lemm'] = combined_df['tokens'].map(lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>text_title</th>\n",
       "      <th>text_length</th>\n",
       "      <th>tokens</th>\n",
       "      <th>text_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>Note 1. Join our IRC, and Telegram chat-rooms!...</td>\n",
       "      <td>162</td>\n",
       "      <td>[Note, 1, Join, our, IRC, and, Telegram, chat,...</td>\n",
       "      <td>note 1 join our irc and telegram chat room ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>394</td>\n",
       "      <td>28</td>\n",
       "      <td>pinionist</td>\n",
       "      <td>Google Maps is getting dedicated car mode UI</td>\n",
       "      <td>9</td>\n",
       "      <td>[Google, Maps, is, getting, dedicated, car, mo...</td>\n",
       "      <td>google map is getting dedicated car mode ui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1077</td>\n",
       "      <td>61</td>\n",
       "      <td>apmcruZ</td>\n",
       "      <td>Tasker lets you intercept Samsung S Pen gestu...</td>\n",
       "      <td>14</td>\n",
       "      <td>[Tasker, lets, you, intercept, Samsung, S, Pen...</td>\n",
       "      <td>tasker let you intercept samsung s pen gesture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1337</td>\n",
       "      <td>184</td>\n",
       "      <td>efbo</td>\n",
       "      <td>22% off nearly everything in European Google ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[22, off, nearly, everything, in, European, Go...</td>\n",
       "      <td>22 off nearly everything in european google store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>294</td>\n",
       "      <td>170</td>\n",
       "      <td>darkstarrising</td>\n",
       "      <td>The new Galaxy S20 FE: $100 off at Amazon and...</td>\n",
       "      <td>13</td>\n",
       "      <td>[The, new, Galaxy, S20, FE, 100, off, at, Amaz...</td>\n",
       "      <td>the new galaxy s20 fe 100 off at amazon and be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit  upvote_ratio  score  num_comments          author  \\\n",
       "0          1          0.81     14            48   AutoModerator   \n",
       "1          1          0.97    394            28       pinionist   \n",
       "2          1          0.97   1077            61         apmcruZ   \n",
       "3          1          0.92   1337           184            efbo   \n",
       "4          1          0.93    294           170  darkstarrising   \n",
       "\n",
       "                                          text_title  text_length  \\\n",
       "0  Note 1. Join our IRC, and Telegram chat-rooms!...          162   \n",
       "1       Google Maps is getting dedicated car mode UI            9   \n",
       "2   Tasker lets you intercept Samsung S Pen gestu...           14   \n",
       "3   22% off nearly everything in European Google ...            9   \n",
       "4   The new Galaxy S20 FE: $100 off at Amazon and...           13   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Note, 1, Join, our, IRC, and, Telegram, chat,...   \n",
       "1  [Google, Maps, is, getting, dedicated, car, mo...   \n",
       "2  [Tasker, lets, you, intercept, Samsung, S, Pen...   \n",
       "3  [22, off, nearly, everything, in, European, Go...   \n",
       "4  [The, new, Galaxy, S20, FE, 100, off, at, Amaz...   \n",
       "\n",
       "                                           text_lemm  \n",
       "0  note 1 join our irc and telegram chat room ple...  \n",
       "1        google map is getting dedicated car mode ui  \n",
       "2  tasker let you intercept samsung s pen gesture...  \n",
       "3  22 off nearly everything in european google store  \n",
       "4  the new galaxy s20 fe 100 off at amazon and be...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customise stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords are very common words that does not add meaning to the documents and hence has no value in helping to classify the documents. The NLTK stopword list was used to remove the highly common words during vectorizing pre-processing step below. From the EDA process, additional words which come up frequently in both subreddits such as \"app\" and \"iphone\" would be removed as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# nltk stopword list\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# add additional stopwords\n",
    "additional_stopwords = {'app'}\n",
    "stop_words = stop_words.union(additional_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with text as a predictor\n",
    "X = combined_df[['text_lemm','score','num_comments']] \n",
    "y = combined_df['subreddit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_lemm</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>note 1 join our irc and telegram chat room ple...</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google map is getting dedicated car mode ui</td>\n",
       "      <td>394</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tasker let you intercept samsung s pen gesture...</td>\n",
       "      <td>1077</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22 off nearly everything in european google store</td>\n",
       "      <td>1337</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the new galaxy s20 fe 100 off at amazon and be...</td>\n",
       "      <td>294</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>what to expect for iphone 12 model featuring a...</td>\n",
       "      <td>195</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>apple update 13 inch macbook pro with magic ke...</td>\n",
       "      <td>11767</td>\n",
       "      <td>2806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>i wa listening to atp on the throne i lean ove...</td>\n",
       "      <td>4686</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>matthew cassinelli apple should enable io devi...</td>\n",
       "      <td>4901</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>unlock your iphone with face id while wearing ...</td>\n",
       "      <td>116</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1763 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_lemm  score  num_comments\n",
       "0     note 1 join our irc and telegram chat room ple...     14            48\n",
       "1           google map is getting dedicated car mode ui    394            28\n",
       "2     tasker let you intercept samsung s pen gesture...   1077            61\n",
       "3     22 off nearly everything in european google store   1337           184\n",
       "4     the new galaxy s20 fe 100 off at amazon and be...    294           170\n",
       "...                                                 ...    ...           ...\n",
       "1758  what to expect for iphone 12 model featuring a...    195            71\n",
       "1759  apple update 13 inch macbook pro with magic ke...  11767          2806\n",
       "1760  i wa listening to atp on the throne i lean ove...   4686           552\n",
       "1761  matthew cassinelli apple should enable io devi...   4901           349\n",
       "1762  unlock your iphone with face id while wearing ...    116            98\n",
       "\n",
       "[1763 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "1758    0\n",
       "1759    0\n",
       "1760    0\n",
       "1761    0\n",
       "1762    0\n",
       "Name: subreddit, Length: 1763, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Feature Selection Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification metric used will be the **accuracy** which is a measure of the proportion of true predictions over all predictions ($\\frac {TP + TN}{TP + TN + FP + FN}$), as there is no class imbalance in the dataset. \n",
    "\n",
    "Two learning algorithms are evaluated: 1) **multinomial Naive Bayes**, and 2) **logistic regression**, using the following combination of preprocessing methods and hyperparameters in the gridsearch param_grid:\n",
    "\n",
    "- `Vectoriser`: count vectorizer/ TF-IDF vectorizer\n",
    "- `Max features`: 2000/ 3000/ 4000/ 5000/ 5500\n",
    "- `Max document frequency`: 0.1/ 0.5/ 0.9/ 0.95\n",
    "- `Min document frequency`: 1/ 2/ 3\n",
    "- `N-gram range`: (1,1)/ (1,2)/ (1,3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.53148\n",
       "1    0.46852\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model would predict class 0 (r/apple) for all posts, since it has a slightly higher percentage (53.1%) than r/android. Hence, baseline accuracy score is 53.1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-title as predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1200 out of 1200 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Best score: 0.95177304964539\n",
      "{'vectorizer': TfidfVectorizer(max_df=0.5, max_features=4000, ngram_range=(1, 2),\n",
      "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
      "                            'ain', 'all', 'am', 'an', 'and', 'any', 'app',\n",
      "                            'are', 'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                            'because', 'been', 'before', 'being', 'below',\n",
      "                            'between', 'both', 'but', 'by', 'can', 'couldn', ...}), 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 4000, 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 2)}\n",
      "\\Score on training set: 0.9879432624113476\n"
     ]
    }
   ],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x:x['text_lemm'], validate=False)),\n",
    "    ('vectorizer', None),\n",
    "    ('logreg', LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "# specify the param grid for gridsearch, which includes different feature selection methods\n",
    "pipe_params = [{\n",
    "   \n",
    "        'vectorizer': [CountVectorizer(stop_words = stop_words),\n",
    "                       TfidfVectorizer(stop_words = stop_words)],\n",
    "        'vectorizer__max_features': [3000, 3500, 4000, 4500, 5000],\n",
    "        'vectorizer__max_df': [0.2, 0.5, 0.9, 0.95],\n",
    "        'vectorizer__min_df': [1, 2],    \n",
    "        'vectorizer__ngram_range': [(1,1), (1,2),(1,3)]\n",
    "        \n",
    "    }]\n",
    "\n",
    "# perform gridsearch for the best feature selection, model, etc\n",
    "gs_text = GridSearchCV(pipe, cv=5, param_grid=pipe_params, scoring = 'accuracy', verbose=True)\n",
    "gs_text.fit(X_train, y_train)\n",
    "print(f\"\\Best score: {gs_text.best_score_}\")\n",
    "print(gs_text.best_params_)\n",
    "    \n",
    "print(f\"\\Score on training set: {gs_text.score(X_train, y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_r/apple</th>\n",
       "      <th>pred_r/android</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_r/apple</th>\n",
       "      <td>181</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_r/android</th>\n",
       "      <td>13</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pred_r/apple  pred_r/android\n",
       "actual_r/apple             181               7\n",
       "actual_r/android            13             152"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_text = gs_text.predict(X_test)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, preds_text) \n",
    "\n",
    "cm_df = pd.DataFrame(data = cm, columns = ['pred_r/apple','pred_r/android'], index =['actual_r/apple','actual_r/android'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_text.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.DataFrame(gs_text.cv_results_)\n",
    "# results = results.sort_values(by='mean_test_score', ascending=False)\n",
    "# results[['param_vectorizer', 'param_vectorizer__max_features', 'mean_test_score',\n",
    "#          'param_vectorizer__min_df', 'param_vectorizer__ngram_range'\n",
    "#        ]].round(3).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Best score: 0.9368794326241134\n",
      "{'vectorizer': TfidfVectorizer(max_df=0.5, max_features=3000, min_df=3, ngram_range=(1, 2),\n",
      "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
      "                            'ain', 'all', 'am', 'an', 'and', 'any', 'app',\n",
      "                            'are', 'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                            'because', 'been', 'before', 'being', 'below',\n",
      "                            'between', 'both', 'but', 'by', 'can', 'couldn', ...}), 'vectorizer__max_df': 0.5, 'vectorizer__max_features': 3000, 'vectorizer__min_df': 3, 'vectorizer__ngram_range': (1, 2)}\n",
      "\\Score on training set: 0.9765957446808511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  3.1min finished\n"
     ]
    }
   ],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x:x['text_lemm'], validate=False)),\n",
    "    ('vectorizer', None),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# specify the param grid for gridsearch, which includes different feature selection methods\n",
    "pipe_params = [{\n",
    "   \n",
    "        'vectorizer': [CountVectorizer(stop_words = stop_words),\n",
    "                       TfidfVectorizer(stop_words = stop_words)],\n",
    "        'vectorizer__max_features': [2000, 3000, 4000, 5000, 5500],\n",
    "        'vectorizer__max_df': [0.1, 0.5, 0.9, 0.95],\n",
    "        'vectorizer__min_df': [1, 2, 3],    \n",
    "        'vectorizer__ngram_range': [(1,1), (1,2),(1,3)]\n",
    "        \n",
    "    }]\n",
    "\n",
    "# perform gridsearch for the best feature selection, model, etc\n",
    "gs_text = GridSearchCV(pipe, cv=5, param_grid=pipe_params, scoring = 'accuracy', verbose=True)\n",
    "gs_text.fit(X_train, y_train)\n",
    "print(f\"\\Best score: {gs_text.best_score_}\")\n",
    "print(gs_text.best_params_)\n",
    "    \n",
    "print(f\"\\Score on training set: {gs_text.score(X_train, y_train)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score and comment counts as predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score and comment counts for both subreddits were added to the predictors to examine whether they help to improve the classification performance. The numerical features were scaled and transformed using RobustScaler to reduce the influence of the extreme outliers (shown by earlier EDA) by removing the median and scaling the data according to the interquartile range.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Best score: 0.9482269503546099\n",
      "{'union__text__vectorizer': TfidfVectorizer(max_df=0.5, max_features=3000, ngram_range=(1, 2),\n",
      "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
      "                            'ain', 'all', 'am', 'an', 'and', 'any', 'app',\n",
      "                            'are', 'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                            'because', 'been', 'before', 'being', 'below',\n",
      "                            'between', 'both', 'but', 'by', 'can', 'couldn', ...}), 'union__text__vectorizer__max_df': 0.5, 'union__text__vectorizer__max_features': 3000, 'union__text__vectorizer__min_df': 1, 'union__text__vectorizer__ngram_range': (1, 2)}\n",
      "\\Score on training set: 0.9836879432624114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  3.7min finished\n"
     ]
    }
   ],
   "source": [
    "# text pipeline\n",
    "text_pipe = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x:x['text_lemm'], validate=False)),\n",
    "    ('vectorizer', None)\n",
    "])\n",
    "\n",
    "# numerical pipeline\n",
    "numerical_pipe = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x:x[['score', 'num_comments']], validate = False)),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# combine pipelines with FeatureUnion\n",
    "overall_pipe = Pipeline([\n",
    "    ('union', FeatureUnion([('text',text_pipe),\n",
    "                            ('numerical',numerical_pipe)])),\n",
    "    ('logreg', LogisticRegression(solver='liblinear'))])\n",
    "\n",
    "\n",
    "# specify the param grid for gridsearch, which includes different feature selection methods\n",
    "pipe_params = [{\n",
    "   \n",
    "        'union__text__vectorizer': [CountVectorizer(stop_words = stop_words),\n",
    "                                    TfidfVectorizer(stop_words = stop_words)],\n",
    "        'union__text__vectorizer__max_features': [2000, 3000, 4000, 5000, 5500],\n",
    "        'union__text__vectorizer__max_df': [0.1, 0.5, 0.9, 0.95],\n",
    "        'union__text__vectorizer__min_df': [1, 2, 3],    \n",
    "        'union__text__vectorizer__ngram_range': [(1,1), (1,2),(1,3)]\n",
    "        \n",
    "    }]\n",
    "\n",
    "# perform gridsearch for the best feature selection, model, etc\n",
    "gs_text_num = GridSearchCV(overall_pipe, cv=5, param_grid=pipe_params, scoring = 'accuracy', verbose=True)\n",
    "gs_text_num.fit(X_train, y_train)\n",
    "print(f\"\\Best score: {gs_text_num.best_score_}\")\n",
    "print(gs_text_num.best_params_)\n",
    "    \n",
    "print(f\"\\Score on training set: {gs_text_num.score(X_train, y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Best score: 0.9361702127659575\n",
      "{'union__text__vectorizer': TfidfVectorizer(max_df=0.5, max_features=3000, ngram_range=(1, 3),\n",
      "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
      "                            'ain', 'all', 'am', 'an', 'and', 'any', 'app',\n",
      "                            'are', 'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                            'because', 'been', 'before', 'being', 'below',\n",
      "                            'between', 'both', 'but', 'by', 'can', 'couldn', ...}), 'union__text__vectorizer__max_df': 0.5, 'union__text__vectorizer__max_features': 3000, 'union__text__vectorizer__min_df': 1, 'union__text__vectorizer__ngram_range': (1, 3)}\n",
      "\\Score on training set: 0.9773049645390071\n"
     ]
    }
   ],
   "source": [
    "# text pipeline\n",
    "text_pipe = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x:x['text_lemm'], validate=False)),\n",
    "    ('vectorizer', None)\n",
    "])\n",
    "\n",
    "# numerical pipeline\n",
    "numerical_pipe = Pipeline([\n",
    "    ('selector', FunctionTransformer(lambda x:x[['score', 'num_comments']], validate = False)),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# combine pipelines with FeatureUnion\n",
    "overall_pipe = Pipeline([\n",
    "    ('union', FeatureUnion([('text',text_pipe),\n",
    "                            ('numerical',numerical_pipe)])),\n",
    "    ('nb', MultinomialNB())])\n",
    "\n",
    "\n",
    "# specify the param grid for gridsearch, which includes different feature selection methods\n",
    "pipe_params = [{\n",
    "   \n",
    "        'union__text__vectorizer': [CountVectorizer(stop_words = stop_words),\n",
    "                                    TfidfVectorizer(stop_words = stop_words)],\n",
    "        'union__text__vectorizer__max_features': [2000, 3000, 4000, 5000, 5500],\n",
    "        'union__text__vectorizer__max_df': [0.1, 0.5, 0.9, 0.95],\n",
    "        'union__text__vectorizer__min_df': [1, 2, 3],    \n",
    "        'union__text__vectorizer__ngram_range': [(1,1), (1,2),(1,3)]\n",
    "        \n",
    "    }]\n",
    "\n",
    "# perform gridsearch for the best feature selection, model, etc\n",
    "gs_text_num = GridSearchCV(overall_pipe, cv=5, param_grid=pipe_params, scoring = 'accuracy', verbose=True)\n",
    "gs_text_num.fit(X_train, y_train)\n",
    "print(f\"\\Best score: {gs_text_num.best_score_}\")\n",
    "print(gs_text_num.best_params_)\n",
    "    \n",
    "print(f\"\\Score on training set: {gs_text_num.score(X_train, y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model results are sumamrised in the table below. In general, the performance of all four models are fairly similar with Logistic Regression models slightly outperforming Multinomial Naive Bayes models under the cross validation accuracy scores. There is some degree of overfitting in all the four models with about 4% variance between the training and cross validation accuracy scores. \n",
    "\n",
    "For logistic regression, it can also be seen that adding the score and comment count numerical features did not improve the accuracy scores. Hence, the **Logistic Regression model using title-text as a predictor** will be chosen for the production model. Regularisation techniques such as Lasso and Ridge will be examined next to check whether it could result in a more generalised model.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Predictors |Model |Train Score |Cross Validation Score  \t|   \t|\n",
    "|---\t|---\t      |---\t        |---\t|---\t|\n",
    "|Text-title \t|Logistic Regression   \t      |0.986          \t|0.948   \t|   \t|\n",
    "|Text-title   \t|Multinomial Naive Bayes   \t      |0.976   \t        |0.937   \t|   \t|\n",
    "|Text-title + score and comment counts    |Logistic Regression   \t      |0.984   \t        |0.948   \t|   \t|\n",
    "|Text-title + score and comment counts \t|Multinomial Naive Bayes   \t      |0.977          \t|0.936   \t|   \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate tvec model with best parameters.\n",
    "tvec = TfidfVectorizer(max_df=0.5, max_features=4000, min_df=1, ngram_range=(1,2), stop_words=stop_words)\n",
    "\n",
    "# Fit and transform model\n",
    "X_train_tvec = tvec.fit_transform(X_train['text_lemm'], y_train).todense()\n",
    "X_test_tvec = tvec.transform(X_test['text_lemm']).todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate logistic regression model\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# specify param grid\n",
    "log_reg_params = {\n",
    "    'C': np.logspace(-2,0,num=50),\n",
    "    'penalty': [\"l1\", \"l2\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.950354609929078\n",
      "{'C': 0.8286427728546842, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# perform grid search \n",
    "gs_logreg = GridSearchCV(logreg, param_grid=log_reg_params, cv=5)\n",
    "gs_logreg.fit(X_train_tvec, y_train)\n",
    "\n",
    "print(f\"Best score: {gs_logreg.best_score_}\")\n",
    "print(gs_logreg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on training set: 0.9872340425531915\n",
      "Accuracy Score on testing set: 0.9405099150141643\n"
     ]
    }
   ],
   "source": [
    "# Re-initialise logistic regression with the best params\n",
    "logreg = LogisticRegression(C=0.8286427728546842, penalty = \"l2\", solver='liblinear')\n",
    "logreg.fit(X_train_tvec, y_train)\n",
    "\n",
    "print('Accuracy Score on training set:', logreg.score(X_train_tvec, y_train))\n",
    "print('Accuracy Score on testing set:', logreg.score(X_test_tvec, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_r/apple</th>\n",
       "      <th>predict_r/android</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_r/apple</th>\n",
       "      <td>181</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_r/android</th>\n",
       "      <td>14</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  predict_r/apple  predict_r/android\n",
       "actual_r/apple                181                  7\n",
       "actual_r/android               14                151"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate confusion matrix\n",
    "preds_text = logreg.predict(X_test_tvec)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds_text) \n",
    "cm_df = pd.DataFrame(data = cm, columns = ['predict_r/apple','predict_r/android'], index =['actual_r/apple','actual_r/android'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model performed well against the unseen test dataset after ridge regularisation (L2 penalty) with an overall accuracy score of 93.9%. From the above confusion matrix, it can observed that there is no clear bias in misclassifying either apple or android subreddits with an inaccuracy of only 5.3% and 7.1% respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top word features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>android</th>\n",
       "      <td>7.776166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>6.672145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>5.275226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixel</th>\n",
       "      <td>4.588497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>galaxy</th>\n",
       "      <td>4.257234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef\n",
       "android  7.776166\n",
       "google   6.672145\n",
       "samsung  5.275226\n",
       "pixel    4.588497\n",
       "galaxy   4.257234"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get coefficient column labels\n",
    "index = tvec.get_feature_names()\n",
    "\n",
    "# Generate dataframe of features with coefficients\n",
    "logreg_coef_df = pd.DataFrame(logreg.coef_[0],\n",
    "                         columns=[\"coef\"],\n",
    "                         index=index)\n",
    "# sort for highest coefficient\n",
    "logreg_coef_df = logreg_coef_df.sort_values(\"coef\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# isolate top and bottom coefficients\n",
    "logreg_coef_odds = pd.concat(objs=[logreg_coef_df.head(10), logreg_coef_df.tail(10)])\n",
    "\n",
    "# plot most significant coefficients\n",
    "plt.figure(figsize=(10, 7))\n",
    "#custom_pal = sns.diverging_palette(197, 28, as_cmap=True)\n",
    "\n",
    "sns.barplot(data=logreg_coef_odds,\n",
    "            x=\"coef\",\n",
    "            y=logreg_coef_odds.index,\n",
    "            palette=\"RdBu_r\",\n",
    "           saturation=0.75)\n",
    "plt.title(\"Top Features for Classifying Subreddit\", size=20)\n",
    "plt.yticks(size=12)\n",
    "plt.xticks(size=12)\n",
    "plt.ylabel(\"Word Feature\", size=16)\n",
    "plt.xlabel(\"Model Coefficient\\n(Log-Odds of being from r/Android)\", size=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above bar chart, it can be observed that the top 5 key words e.g. \"android\", \"google\", \"samsung\", \"pixel\" and \"galaxy\" that helped to classify postings as being from r/Android (positive class '1') were also found in the top 10 common words identified in the EDA. It is also interesting to note that some words with the lowest coefficient e,g, \"mac\", \"12\" and \"airpods\" were not from the top 10 common words in r/apple, which could be attributed to the TF-IDF vectorizer according higher weights to rarer words which appear in just a handful of documents.  \n",
    "\n",
    "The logistic model coefficients corresponds to the log odds of the posting being from r/Android as word feature increases by 1 unit, and they could be exponentiated to derive the real odds. For example, as 'android' word feature increases by 1 unit, the log-odds of the post being from r/Android subreddit increase by 7.8 times (or 2383 times as likely).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>android</th>\n",
       "      <td>7.776166</td>\n",
       "      <td>2383.120812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>6.672145</td>\n",
       "      <td>790.088742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>5.275226</td>\n",
       "      <td>195.434726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixel</th>\n",
       "      <td>4.588497</td>\n",
       "      <td>98.346472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>galaxy</th>\n",
       "      <td>4.257234</td>\n",
       "      <td>70.614386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef         odds\n",
       "android  7.776166  2383.120812\n",
       "google   6.672145   790.088742\n",
       "samsung  5.275226   195.434726\n",
       "pixel    4.588497    98.346472\n",
       "galaxy   4.257234    70.614386"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute odds from model coefficients\n",
    "logreg_coef_odds[\"odds\"] = logreg_coef_odds.apply(lambda x: np.exp(x))\n",
    "logreg_coef_odds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-3.420171</td>\n",
       "      <td>0.032707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-3.721701</td>\n",
       "      <td>0.024193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mac</th>\n",
       "      <td>-3.811723</td>\n",
       "      <td>0.022110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>io</th>\n",
       "      <td>-5.764327</td>\n",
       "      <td>0.003138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>-11.662120</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            coef      odds\n",
       "14     -3.420171  0.032707\n",
       "12     -3.721701  0.024193\n",
       "mac    -3.811723  0.022110\n",
       "io     -5.764327  0.003138\n",
       "apple -11.662120  0.000009"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Odds of word features with lowest coefficients\n",
    "logreg_coef_odds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
